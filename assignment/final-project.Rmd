---
title: 'Anti-Deforestation Policies and Changes in the Clearings Pattern: Brazilian
  Amazon Case'
author: "Joao Pedro Vieira"
date: "November 25, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = FALSE, warning = F, message = F)
```


### Loading Libraries
```{r libraries, include= TRUE, message = F}
library(tidyverse)    # to manipulate data
library(sf)           # to work with simple features data
library(XML)          # XML for HTML processing
library(utils)        # for 'unzip' function
library(RColorBrewer) # for color palettes
library(gridExtra)    # for organizing multiple plots
``` 

### Functions (create separate file and source it)

```{r}
UnzipMultipleFolders <- function(zip.dir,
                                 zip.pattern  = ".zip",
                                 unzip.subdir = T) {
    # UNZIPS FOLDERS IN GIVEN DIRECTORY & > 
    # SUBDIRECTORIES AND DELETES COMPRESSED FOLDERS
    #
    # ARGS
    #   zip.dir:      parent directory containing zip files
    #   zip.pattern:  zipped file extension
    #   unzip.subdir: if TRUE, looks for 'zip.pattern' subdirs in 'zip.dir' >
    #                 (but does not find nested compressed dirs - >
    #                  'while' loop in function addresses this)
    #
    # RETURN
    # unzipped folders in equivalent directory structure
  
      # zipped folder identification 
      zip_list <- list.files(path       = zip.dir,
                             pattern    = zip.pattern,
                             recursive  = T,
                             full.names = T)
  
      # unzip procedure
      while (length(zip_list) > 0) {  # 'while' to enable recursive unzip
        
        for (zip_folder in zip_list) {
            unzip_dir <- str_replace(pattern     = zip.pattern,   # sets unzipped dir structure to mirror >
                                     replacement = "",            # original zipped dir structure
                                     string      = zip_folder)
            
            unzip(zipfile   = zip_folder,                       # unzips folders
                  overwrite = T,
                  exdir     = unzip_dir)
        }
  
    map(zip_list, unlink)  # deletes zip files
  
    zip_list <- list.files(path       = zip.dir,       # 'zip.list' updated to check existence of > 
                           pattern    = zip.pattern,   # remaining zip dirs in recently unzipped dirs
                           recursive  = unzip.subdir,
                           full.names = T)
    }
  }


convert.sqm.to.ha   <- 0.0001

crs_SAD69longlatPre96BR <- "+proj=longlat +ellps=aust_SA +towgs84=-66.8700,4.3700,-38.5200,0.0,0.0,0.0,0.0 +no_defs"

crs_SIRGAS2000albers <- "+proj=aea +lat_1=-2 +lat_2=-22 +lat_0=-12 +lon_0=-54 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs"
```



### Data Download


#### Deforestation
```{r}
# web address setup
raw_data_url_index <- "http://www.dpi.inpe.br/prodesdigital/dadosn/2014/"


# directory setup
raw_data_dir <- "data_input" 

# download of 2015 shapefile data
  if (!dir.exists(paths = raw_data_dir)) { # check existence of "data_input" folder
    dir.create(path  = raw_data_dir)
    print(paste0("***NOTE: directory ", raw_data_dir, " created."))
  }
  
  
  if (length(list.files(raw_data_dir)) == 0) {
  
    html_matched  <- 
      htmlParse(raw_data_url_index) %>%           # parses html string (splits into components)
      getNodeSet("//a") %>%                       # finds nodes matching criterion "//a"
      map(xmlGetAttr, "href") %>% 
      grep(pattern = "*_shp.zip", value = T)      # selects elements matching "*_shp.zip" (returns landsat mosaic scenes)
  
    
    raw_data_url_zipfiles <- paste(raw_data_url_index, html_matched,
                                   sep = "")
    
    dest_path <- file.path(raw_data_dir, html_matched)
    
    map2(raw_data_url_zipfiles, dest_path, function(x,y) download.file(x,y))  # name determined in 'html_matched'
    
    
    UnzipMultipleFolders(zip.dir      = raw_data_dir,    # unzips downloaded data and deletes original compressed files
                         zip.pattern  = ".zip",
                         unzip.subdir = T)

}


```

#### Legal Aamazon - State Boundaries

```{r}
if (!file.exists(file.path(raw_data_dir, "UF_AmLeg_LLwgs84"))) { # only download data if there is not a local copy
  
  raw_data_url_index_2 <- "http://www.dpi.inpe.br/amb_data/Shapefiles/UF_AmLeg_LLwgs84.zip" # set url 
  
  download.file(url = raw_data_url_index_2, destfile = "data_input/UF_AmLeg_LLwgs84.zip") # download the shapefile
  
  UnzipMultipleFolders(zip.dir      = raw_data_dir,    # unzips downloaded data and deletes original compressed files
                       zip.pattern  = ".zip",
                       unzip.subdir = T)
}
```


### Data Cleaning

#### Deforestation
```{r}

clean_data_dir <- "data_clean"

if (!dir.exists(paths = clean_data_dir)) { # check existence of "data_clean" folder
  dir.create(path  = clean_data_dir)
  print(paste0("***NOTE: directory ", clean_data_dir, " created."))
}


if (!any(list.files(clean_data_dir) == "def_clean.Rdata")) { # check if def_clean.Rdata already exists locally

  folder_name  <- list.files(raw_data_dir, pattern = "_shp") # create a list with all mosaic scene folders
  
  layer_name <- str_replace(pattern = "_shp", replacement = "__pol", string = folder_name) # layer name is very similar to the folder name
  
  complete_path <- file.path(raw_data_dir, folder_name, "2014")
  
  mosaic_scene <- 
    map2(.x = complete_path, .y = layer_name, .f = st_read, quiet = T) 
    
  def_clean <-
    mosaic_scene %>% 
    map(st_set_crs, crs_SAD69longlatPre96BR) %>% # some scenes are missing the proj4string, so we set it based on documentation and existing proj4string 
    map(filter, mainclass == "DESFLORESTAMENTO") %>% # extracting deforestation data
    reduce(rbind) %>% # merging all sf objects into a single one
    
    st_transform(crs_SIRGAS2000albers) %>%  # projecting to "SIRGAS2000albers"
    mutate(area = unclass(st_area(.)) * convert.sqm.to.ha) %>% # create area column and convert it to hectars
    mutate(polyg_id = paste(pathrow, linkcolumn, sep = "_")) %>% # create id column
    mutate(mainclass = as.character(mainclass)) %>% # transform column class from factor to character
    mutate(mainclass = replace(mainclass, mainclass == "DESFLORESTAMENTO", "DEFORESTATION")) %>% # translate mainclass
    rename(state_uf = uf, prodes_class = mainclass, prodes_year_increment = ano) %>%  # adjust columns name
    select(polyg_id, state_uf, prodes_class, prodes_year_increment, area) # keep column of interest
  
  rm(mosaic_scene)
  
  def_clean_df <- # create a version of the clean data with only data.frame information to have a light version of the data
    def_clean %>% 
    st_set_geometry(NULL)
  
  save(def_clean, file = file.path(clean_data_dir, "def_clean.Rdata"))  
  save(def_clean_df, file = file.path(clean_data_dir, "def_clean_df.Rdata"))  

}
```

#### Legal Aamazon - State Boundaries
```{r}


if (!any(list.files(clean_data_dir) == "la_clean.Rdata")) { # check if def_clean.Rdata already exists locally

  folder_name  <- list.files(raw_data_dir, pattern = "AmLeg") # create a list with the Legal Amazon folder
  
  subfolder_name <- str_replace(pattern = "UF", replacement = "UFS", string = folder_name) # subfolder name is very similar to the folder name
  
  layer_name <-     # layer name is very similar to the subfolder name
    toupper(subfolder_name) %>% 
    str_replace(pattern = "AMLEG", replacement = "AMZLEG")

  
  complete_path <- file.path(raw_data_dir, folder_name, subfolder_name)

  la_clean <- 
    st_read(dsn = complete_path, layer = layer_name, quiet = T) %>% 
    st_transform(crs_SIRGAS2000albers) %>% 
    mutate(area = unclass(st_area(.)) * convert.sqm.to.ha) %>% # create area column and convert it to hectars
    rename(state_uf = NOME) %>%  # adjust columns name
    select(state_uf, area, geometry) %>% 
    mutate(state_uf = as.character(state_uf)) %>% 
    mutate(state_uf = if_else(state_uf == "AMAPÁ", "AP", state_uf)) %>% 
    mutate(state_uf = if_else(state_uf == "MATO GROSSO", "MT", state_uf)) %>%
    mutate(state_uf = if_else(state_uf == "RORAIMA", "RR", state_uf)) %>% 
    mutate(state_uf = str_sub(str_to_upper(state_uf),start = 1, end = 2))  # make a uniform pattern  
  

  save(la_clean, file = file.path(clean_data_dir, "la_clean.Rdata"))  

}
```


### Load clean data
```{r}
load(file.path(clean_data_dir, "def_clean_df.Rdata"))

load(file.path(clean_data_dir, "def_clean.Rdata"))

load(file.path(clean_data_dir, "la_clean.Rdata"))

```


### Deforestation Trends by size of cleared patch 

Inspired by **Fig. 1 - Amazon deforestation by the size of cleared forest patch, 2002–2012 - (Assunção et al., 2017)**
![](../images/deforestation_increment_sizes.png)
```{r}
def_clean_df %>% 
  group_by(prodes_year_increment) %>% 
  filter(prodes_year_increment >= 2002) %>% 
  mutate(size = ifelse(area < 25, "small", "large")) %>% 
  group_by(state_uf, prodes_year_increment, size) %>% 
  summarise(area_bysize = sum(area)) %>% 
  spread(key = size, value = area_bysize) %>% 
  replace_na(list(large = 0, small = 0)) %>% 
  rename(def_large = large, def_small = small) %>% 
  mutate(def_total = def_large + def_small) %>% 
  group_by(prodes_year_increment) %>% 
  summarise(sum_def_large = sum(def_large, na.rm = T)/100000, sum_def_small = sum(def_small, na.rm = T)/100000) %>% 
  gather(key = "size", value = "def", -prodes_year_increment) %>% 
  
ggplot(aes(x = prodes_year_increment, y = def, fill = size)) +
  geom_area() +
  scale_fill_manual(name = "Polygon Size", labels = c("Large (>25ha)", "Small (<25ha)"), values = c("coral1", "lightblue")) +
  labs(x = "Year", 
       y = "Deforestation Increment (100,000 ha)", 
       title = "Deforestation Trends by Polygon Size", 
       subtitle = "Inspired by Fig. 1 (Assunção et al., 2017) ",  
       caption = "Notes: Reproducing Fig.1 from Assunção et al. (2017) expanding time period to include 2 more years.\n The figure illustrates annual Brazilian Amazon deforestation increment decomposed by size of cleared forest patch") +
  scale_x_continuous(breaks = c(2002:2014), expand = c(0, 0), limits = c(2002, 2014.2)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), legend.position = "bottom")
```

**Fig. 2 - (a) Percentage and (b) area of deforested patches of different sizes in the Brazilian Amazon from 2002 through 2009. - (Rosa et al., 2012)**
<br>
![](../images/deforestation_rate_percentage_byYear_bySize_rosa_et_al_2012.png)

```{r fig.height = 10}

panel_a <- 
  def_clean_df %>% 
  group_by(prodes_year_increment) %>% 
  filter(prodes_year_increment >= 2002) %>% 
  mutate(size = ifelse(area < 25, "<25 ha", NA)) %>%
  mutate(size = ifelse(area >= 25 & area < 100, "25-100 ha", size)) %>% 
  mutate(size = ifelse(area >= 100 & area < 500, "100-500 ha", size)) %>% 
  mutate(size = ifelse(area >= 500, "> 500 ha", size)) %>% 
  group_by(state_uf, prodes_year_increment, size) %>% 
  summarise(area_bysize = sum(area)) %>% 
  ungroup() %>% 
  mutate(area_bysize = area_bysize/10000) %>% 
  mutate(size = factor(size, levels = c("> 500 ha", "100-500 ha", "25-100 ha", "<25 ha"))) %>% 
  mutate(prodes_year_increment = as.factor(prodes_year_increment)) %>% 

  
ggplot(aes(x = prodes_year_increment, y = area_bysize)) +
  geom_bar(aes(fill = size), stat = "identity", position = "fill") +
  scale_fill_manual(name = "Polygon Size", values = brewer.pal(n = 6, name = "Greys")[2:6]) +
  labs(x = "Year", 
       y = "Deforestation Share",
       title = "Deforestation Trends by Polygon Size",  
       subtitle = "Inspired by Figure 1 - (a) - Rosa et al. (2012)",
       caption = "Notes: Reproducing Fig.1 (a) from Rosa et al. (2012) expanding time period to include 5 more years and different patches.\n The figure illustrates the share of deforested patches of different sizes in the Brazilian Amazon from 2002 through 2009.") +
  scale_x_discrete(breaks = c(2002:2014), expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), legend.position = "bottom")

panel_b <-
  def_clean_df %>% 
  group_by(prodes_year_increment) %>% 
  filter(prodes_year_increment >= 2002) %>% 
  mutate(size = ifelse(area < 25, "<25 ha", NA)) %>%
  mutate(size = ifelse(area >= 25 & area < 100, "25-100 ha", size)) %>% 
  mutate(size = ifelse(area >= 100 & area < 500, "100-500 ha", size)) %>% 
  mutate(size = ifelse(area >= 500, "> 500 ha", size)) %>% 
  group_by(state_uf, prodes_year_increment, size) %>% 
  summarise(area_bysize = sum(area)) %>% 
  ungroup() %>% 
  mutate(area_bysize = area_bysize/10000) %>% 
  mutate(size = factor(size, levels = c("> 500 ha", "100-500 ha", "25-100 ha", "<25 ha"))) %>% 
  mutate(prodes_year_increment = as.factor(prodes_year_increment)) %>% 

  
ggplot(aes(x = prodes_year_increment, y = area_bysize, fill = size)) +
  geom_bar(position = "stack", stat = "identity") +
  scale_fill_manual(name = "Polygon Size", values = brewer.pal(n = 6, name = "Greys")[2:6]) +
  labs(x = "Year", 
       y = "Deforestation rate (10,000 ha/yr)",
       title = "Deforestation Trends by Polygon Size",  
       subtitle = "Inspired by Figure 1 - (b) - Rosa et al. (2012)",
       caption = "Notes: Reproducing Fig.1 (b) from Rosa et al. (2012) expanding time period to include 5 more years and different patches.\n The figure illustrates area of deforested patches of different sizes in the Brazilian Amazon from 2002 through 2009.") +
  scale_x_discrete(breaks = c(2002:2014)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), legend.position = "bottom")


grid.arrange(panel_a, panel_b, ncol = 1)
```


### State Heterogeneity  

Inspired by **Fig. 3 - Deforestation inside registered properties by property and cleared patch size, 2002–2012. - (Assunção et al., 2017)**
![](../images/deforestation_percentage_byState_byYear_bySize.png)

#### Simple Plot of State Boundaries and UFs

```{r}
cbind(la_clean, st_coordinates(st_centroid(la_clean))) %>% 
  ggplot() +
  geom_sf(fill = NA) +
  geom_text(aes(X, Y, label = state_uf), size = 5) +
  labs(x = "Lon", y = "Lat", title = "Map of Legal Amazon - State Boundaries") +
  theme_bw()
```



#### Plot of proportion of polygons by cleared patch through time by state.

```{r fig.height=12, fig.width=10}
def_clean_df %>% 
  group_by(prodes_year_increment) %>% 
  filter(prodes_year_increment >= 2002) %>% 
  mutate(size = ifelse(area < 25, "<25 ha", NA)) %>%
  mutate(size = ifelse(area >= 25 & area < 100, "25-100 ha", size)) %>% 
  mutate(size = ifelse(area >= 100 & area < 500, "100-500 ha", size)) %>% 
  mutate(size = ifelse(area >= 500, "> 500 ha", size)) %>% 
  group_by(state_uf, prodes_year_increment, size) %>% 
  summarise(area_bysize = sum(area)) %>% 
  ungroup() %>% 
  mutate(prodes_year_increment = as.factor(prodes_year_increment)) %>% 
  mutate(size = factor(size, levels = c("> 500 ha", "100-500 ha", "25-100 ha", "<25 ha"))) %>% 
  
ggplot(aes(x = prodes_year_increment, y = area_bysize)) +
  geom_bar(aes(fill = size), stat = "identity", position = "fill") +
  scale_fill_manual(name = "Polygon Size", values = brewer.pal(n = 6, name = "Greys")[2:6]) +
  ylab("Share Polygon Size") +
  xlab("Year") +
  ggtitle("Polygons Trends by State and Cleared Patch Size") +
  scale_x_discrete(breaks = c(2002:2014), expand = c(0,0)) +
  scale_y_continuous(expand = c(0, 0)) +
  facet_wrap(. ~ state_uf, ncol = 2, scales = "free") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), legend.position = "bottom", strip.background = element_rect(fill=NA))
```


#### Maps of the proportion of small polygons across years

```{r fig.height = 14, fig.width = 12}
def_clean_df %>% 
  group_by(prodes_year_increment) %>% 
  filter(prodes_year_increment >= 2002) %>% 
  mutate(size = ifelse(area < 25, "small", "large")) %>% 
  group_by(state_uf, prodes_year_increment, size) %>% 
  summarise(area_bysize = sum(area)) %>% 
  spread(key = size, value = area_bysize) %>% 
  replace_na(list(large = 0, small = 0)) %>% 
  rename(def_large = large, def_small = small) %>% 
  mutate(def_total = def_large + def_small) %>% 
  mutate(share_def_small = def_small/def_total) %>% 
  right_join(la_clean) %>% 
  
ggplot() +
  
  geom_sf(aes(fill = share_def_small)) +
  facet_wrap(. ~ prodes_year_increment, ncol = 4) +
  scale_fill_distiller(type = "seq", palette = "YlOrRd", direction = -1, name = "Share Small Polygon Deforestation") +
  
  theme(panel.grid.major = element_line(colour = "White"), 
        panel.grid.minor = element_line(colour = "white"),
        panel.background = element_blank(), 
        strip.background = element_rect(fill = NA),
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.title = element_blank(), axis.text = element_blank(), 
        legend.position = "bottom", legend.key.width = unit(4, "cm"))

```


#### Maps of the ratio of total deforestation and state area across years

```{r fig.height = 14, fig.width = 12}
def_clean_df %>% 
  group_by(prodes_year_increment) %>% 
  filter(prodes_year_increment >= 2002) %>% 
  group_by(state_uf, prodes_year_increment) %>% 
  summarise(area_def = sum(area)) %>% 
  replace_na(area_def = 0) %>% 
  right_join(la_clean) %>%
  mutate(share_def = area_def/area) %>% 
  
ggplot() +
  
  geom_sf(aes(fill = share_def)) +
  facet_wrap(. ~ prodes_year_increment, ncol = 4) +
  scale_fill_distiller(type = "seq", palette = "YlOrRd", direction = -1, name = "Share of State Deforested Area") +
  
  theme(panel.grid.major = element_line(colour = "White"), 
        panel.grid.minor = element_line(colour = "white"),
        panel.background = element_blank(), 
        strip.background = element_rect(fill = NA),
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.title = element_blank(), axis.text = element_blank(),
        legend.position = "bottom", legend.key.width = unit(4, "cm"))

```


### Spatial Distribution of deforestation by cleared patch size across time (2002-2014) - create function to just change the start and end year

**Fig. 4 - Distribution of deforested patches of different sizes in the Brazilian Amazon for periods of (a) rapidly increasing deforestation (2002 through 2004) and (b) rapidly decreasing deforestation (2005 through 2009).- (Rosa et al., 2012)**

![](../images/deforestation_map_bySize_rosa_et_al_2012.png)

```{r fig.height = 20}
map_1 <-
  def_clean %>% 
  filter(prodes_year_increment >= 2002 & prodes_year_increment <= 2004) %>% 
  mutate(size = ifelse(area < 25, "<25 ha", NA)) %>%
  mutate(size = ifelse(area >= 25 & area < 100, "25-100 ha", size)) %>% 
  mutate(size = ifelse(area >= 100 & area < 500, "100-500 ha", size)) %>% 
  mutate(size = ifelse(area >= 500, "> 500 ha", size)) %>% 
  group_by(state_uf, size) %>% 
  st_union(by_feature = T) %>% 
  ungroup() %>% 
  mutate(size = factor(size, levels = c("> 500 ha", "100-500 ha", "25-100 ha", "<25 ha"))) %>% 
  filter(state_uf == "AC") %>% 
  
ggplot() +
  
  geom_sf(aes(col = size, fill = size), size = 1.05) +
  
  geom_sf(data = la_clean, fill = NA) +
  
  ggtitle("Distribution of deforested patches by size (2002-2004") +
  
   theme(panel.grid.major = element_line(colour = "White"), 
        panel.grid.minor = element_line(colour = "white"),
        panel.background = element_blank(), 
        strip.background = element_rect(fill = NA),
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.title = element_blank(), axis.text = element_blank(),
        legend.position = "bottom")

map_2 <-
  def_clean %>% 
  filter(prodes_year_increment >= 2005 & prodes_year_increment <= 2009) %>% 
  mutate(size = ifelse(area < 25, "<25 ha", NA)) %>%
  mutate(size = ifelse(area >= 25 & area < 100, "25-100 ha", size)) %>% 
  mutate(size = ifelse(area >= 100 & area < 500, "100-500 ha", size)) %>% 
  mutate(size = ifelse(area >= 500, "> 500 ha", size)) %>% 
  group_by(state_uf, size) %>% 
  st_union(by_feature = T) %>% 
  ungroup() %>% 
  mutate(size = factor(size, levels = c("> 500 ha", "100-500 ha", "25-100 ha", "<25 ha"))) %>% 
    filter(state_uf == "AC") %>% 

  
ggplot() +
  
  geom_sf(aes(col = size, fill = size), size = 1.05) +
  
  geom_sf(data = la_clean, fill = NA) +
  
  ggtitle("Distribution of deforested patches by size (2005-2009)") +

  
   theme(panel.grid.major = element_line(colour = "White"), 
        panel.grid.minor = element_line(colour = "white"),
        panel.background = element_blank(), 
        strip.background = element_rect(fill = NA),
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.title = element_blank(), axis.text = element_blank(),
        legend.position = "bottom")

map_3 <-
  def_clean %>% 
  filter(prodes_year_increment >= 2009) %>% 
  mutate(size = ifelse(area < 25, "<25 ha", NA)) %>%
  mutate(size = ifelse(area >= 25 & area < 100, "25-100 ha", size)) %>% 
  mutate(size = ifelse(area >= 100 & area < 500, "100-500 ha", size)) %>% 
  mutate(size = ifelse(area >= 500, "> 500 ha", size)) %>% 
  group_by(state_uf, size) %>% 
  st_union(by_feature = T) %>% 
  ungroup() %>% 
  mutate(size = factor(size, levels = c("> 500 ha", "100-500 ha", "25-100 ha", "<25 ha"))) %>% 
    filter(state_uf == "AC") %>% 

  
ggplot() +
  
  geom_sf(aes(col = size, fill = size), size = 1.05) +
  
  geom_sf(data = la_clean, fill = NA) +
  
  ggtitle("Distribution of deforested patches by size (2009-2014)") +

  
   theme(panel.grid.major = element_line(colour = "White"), 
        panel.grid.minor = element_line(colour = "white"),
        panel.background = element_blank(), 
        strip.background = element_rect(fill = NA),
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.title = element_blank(), axis.text = element_blank(),
        legend.position = "bottom")

grid.arrange(map_1, map_2, map_3, ncol = 1)

```




